{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d0b31e-bd64-4c44-82a6-ec3c8cf02bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select last_run_timestamp from etl_log where id = (select max(id) from etl_log);\n",
      "1990-01-01 00:00:00\n",
      "select column_name from information_Schema.columns where table_name='product_information' and table_schema='buy_online' order by ordinal_position;\n",
      "select id,product_name,category,price,created,last_updated from buy_online.product_information where created>='1990-01-01 00:00:00' or last_updated>='1990-01-01 00:00:00' limit 10;\n",
      "['id', 'product_name', 'category', 'price', 'created', 'last_updated']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>created</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sofa</td>\n",
       "      <td>Houseold</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupboard</td>\n",
       "      <td>Shopping Mart</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cupboard</td>\n",
       "      <td>Shopping Mart</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wires</td>\n",
       "      <td>Office</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cupboard</td>\n",
       "      <td>Educational Institutions</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Cupboard</td>\n",
       "      <td>Houseold</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Adaptor</td>\n",
       "      <td>Shopping Mart</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sofa</td>\n",
       "      <td>Office</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Bottle</td>\n",
       "      <td>Houseold</td>\n",
       "      <td>790.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Sofa</td>\n",
       "      <td>Educational Institutions</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "      <td>2024-07-28 13:32:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id product_name                  category    price             created  \\\n",
       "0   1         Sofa                  Houseold  25000.0 2024-07-28 13:32:58   \n",
       "1   2     Cupboard             Shopping Mart  20000.0 2024-07-28 13:32:58   \n",
       "2   3     Cupboard             Shopping Mart  10000.0 2024-07-28 13:32:58   \n",
       "3   4        Wires                    Office  20000.0 2024-07-28 13:32:58   \n",
       "4   5     Cupboard  Educational Institutions    300.0 2024-07-28 13:32:58   \n",
       "5   6     Cupboard                  Houseold  25000.0 2024-07-28 13:32:58   \n",
       "6   7      Adaptor             Shopping Mart    300.0 2024-07-28 13:32:58   \n",
       "7   8         Sofa                    Office   4000.0 2024-07-28 13:32:58   \n",
       "8   9       Bottle                  Houseold    790.0 2024-07-28 13:32:58   \n",
       "9  10         Sofa  Educational Institutions   3000.0 2024-07-28 13:32:58   \n",
       "\n",
       "         last_updated  \n",
       "0 2024-07-28 13:32:58  \n",
       "1 2024-07-28 13:32:58  \n",
       "2 2024-07-28 13:32:58  \n",
       "3 2024-07-28 13:32:58  \n",
       "4 2024-07-28 13:32:58  \n",
       "5 2024-07-28 13:32:58  \n",
       "6 2024-07-28 13:32:58  \n",
       "7 2024-07-28 13:32:58  \n",
       "8 2024-07-28 13:32:58  \n",
       "9 2024-07-28 13:32:58  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddhant.rawat\\AppData\\Local\\Temp\\ipykernel_15224\\1154345352.py:130: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  producer.produce(topic='kafka-topic-product',key=str(row[0]),value=value,on_delivery=delivery_report)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User record b'1' successfully produced to kafka-topic-product [3] at offset 1\n",
      "User record b'2' successfully produced to kafka-topic-product [7] at offset 1\n",
      "User record b'3' successfully produced to kafka-topic-product [1] at offset 3\n",
      "User record b'4' successfully produced to kafka-topic-product [8] at offset 1\n",
      "User record b'5' successfully produced to kafka-topic-product [6] at offset 2\n",
      "User record b'6' successfully produced to kafka-topic-product [0] at offset 1\n",
      "User record b'7' successfully produced to kafka-topic-product [6] at offset 3\n",
      "User record b'8' successfully produced to kafka-topic-product [1] at offset 4\n",
      "User record b'9' successfully produced to kafka-topic-product [9] at offset 1\n",
      "User record b'10' successfully produced to kafka-topic-product [1] at offset 5\n",
      "All data successfully published\n",
      "insert into  etl_log (last_run_timestamp) values ('2024-07-28 17:34:22.476411');\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Following are the steps that the producer follows to produce the data\n",
    "1. Connect to mysql server\n",
    "2.fetch the data from the table incrementally\n",
    "3.creates a kafka connection and publishes data to the topic\n",
    "4.Updates the incremental date back to the etl table\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import mysql.connector\n",
    "from confluent_kafka import SerializingProducer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "from confluent_kafka.serialization import StringSerializer\n",
    "\n",
    "etl_table = 'etl_log'\n",
    "table_name = 'product_information'\n",
    "schema_name = 'buy_online'\n",
    "\n",
    "\n",
    "def connect_mysql():\n",
    "    \"\"\"\n",
    "    This function is used to establish connection to mysql server and fetch the details required to pull the data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #print(\"I am here\")\n",
    "    config = {\n",
    "        'user': 'root',\n",
    "        'host': 'localhost',\n",
    "        'password': 'admin',\n",
    "        'database': 'buy_online',\n",
    "        'raise_on_warnings': True\n",
    "    }\n",
    "\n",
    "    cnx = mysql.connector.connect(**config)\n",
    "    my_cursor = cnx.cursor()\n",
    "\n",
    "    # Get the last_run_timestamp of the etl from the database\n",
    "\n",
    "    get_last_run_timestamp = \"select last_run_timestamp from \" + etl_table + \" where id = (select max(id) from \" + etl_table + \");\"\n",
    "    print(get_last_run_timestamp)\n",
    "    my_cursor.execute(get_last_run_timestamp)\n",
    "    last_run_timestamp = my_cursor.fetchall()\n",
    "\n",
    "    last_run_timestamp = pd.DataFrame(last_run_timestamp)\n",
    "    print(last_run_timestamp[0][0])\n",
    "\n",
    "    fetch_data_from_table(my_cursor, last_run_timestamp[0][0])\n",
    "    \n",
    "    cnx.commit()\n",
    "    cnx.close()\n",
    "\n",
    "\n",
    "def fetch_data_from_table(my_cursor, last_run):\n",
    "    get_data = \"select column_name from information_Schema.columns where table_name='\" + table_name + \"' and table_schema='\" + schema_name + \\\n",
    "               \"' order by ordinal_position;\"\n",
    "    print(get_data)\n",
    "\n",
    "    my_cursor.execute(get_data)\n",
    "    column_names = pd.DataFrame(my_cursor.fetchall())\n",
    "\n",
    "    #display(column_names)\n",
    "\n",
    "    # create the select query\n",
    "    col_list=[]\n",
    "    sel_query = \"select \"\n",
    "    for idx, col in column_names.iterrows():\n",
    "        sel_query += col[0] + \",\"\n",
    "        col_list.append(col[0])\n",
    "    sel_query = sel_query[:-1] + \" from \" + schema_name + \".\" + table_name + \" where created>='\" + str(last_run) + \\\n",
    "                \"' or last_updated>='\" + str(last_run) + \"' limit 10;\"\n",
    "    print(sel_query)\n",
    "    print(col_list)\n",
    "\n",
    "    kafka_producer(sel_query, my_cursor,col_list)\n",
    "\n",
    "\n",
    "def kafka_producer(sel_query, my_cursor,col_list):\n",
    "    my_cursor.execute(sel_query)\n",
    "    product_data = pd.DataFrame(my_cursor.fetchall(),columns=col_list)\n",
    "    display(product_data.head(10))\n",
    "\n",
    "    create_kafka_connection(product_data)\n",
    "\n",
    "    date_update(my_cursor)\n",
    "\n",
    "\n",
    "def create_kafka_connection(product_data):\n",
    "    kafka_config = {\n",
    "        'bootstrap.servers': 'pkc-l7pr2.ap-south-1.aws.confluent.cloud:9092',\n",
    "        'sasl.mechanisms': 'PLAIN',\n",
    "        'security.protocol': 'SASL_SSL',\n",
    "        'sasl.username': 'P2AIJEUTB2XQGESS',\n",
    "        'sasl.password': 'l5wKwZ6dXVTKhYjRjg/LvumvUXmlurP7AB36X6g6i1PgdQsNAMtzJJQ+b/PAS9RF'\n",
    "    }\n",
    "\n",
    "    # create a schema registry client\n",
    "\n",
    "    create_schema_registry_client = SchemaRegistryClient({\n",
    "        'url': 'https://psrc-gqrvzv.southeastasia.azure.confluent.cloud',\n",
    "        'basic.auth.user.info': '{}:{}'.format('NWIGQODEMAQLNVHG',\n",
    "                                               'srLL0tbfwYYRjsF6LvawiZArZXVYuF1g9/rQWGzi4qz2Zm3kBrUwlX0vinzsyqjH')\n",
    "    })\n",
    "\n",
    "    # fetch the latest avro schema\n",
    "    subject_name = 'kafka-topic-product-value'\n",
    "    schema_str = create_schema_registry_client.get_latest_version(subject_name).schema.schema_str\n",
    "\n",
    "    key_serializer=StringSerializer('UTF-8')\n",
    "    avro_serializer=AvroSerializer(create_schema_registry_client,schema_str)\n",
    "\n",
    "    #establish connection to the producer\n",
    "\n",
    "    producer=SerializingProducer({\n",
    "        'bootstrap.servers':kafka_config['bootstrap.servers'],\n",
    "        'sasl.mechanisms':kafka_config['sasl.mechanisms'],\n",
    "        'security.protocol':kafka_config['security.protocol'],\n",
    "        'sasl.username':kafka_config['sasl.username'],\n",
    "        'sasl.password':kafka_config['sasl.password'],\n",
    "        'key.serializer':key_serializer,\n",
    "        'value.serializer':avro_serializer\n",
    "    })\n",
    "\n",
    "    for idx,row in product_data.iterrows():\n",
    "        value=row.to_dict()\n",
    "        #print(value)\n",
    "        producer.produce(topic='kafka-topic-product',key=str(row[0]),value=value,on_delivery=delivery_report)\n",
    "        producer.flush()\n",
    "        time.sleep(2)\n",
    "\n",
    "    print(\"All data successfully published\")\n",
    "\n",
    "def delivery_report(err,msg):\n",
    "\n",
    "    if err is not None:\n",
    "        print(\"Delivery failed for User record {}: {}\".format(msg.key(), err))\n",
    "        return\n",
    "    print('User record {} successfully produced to {} [{}] at offset {}'.format(\n",
    "        msg.key(), msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "\n",
    "def date_update(my_cursor):\n",
    "\n",
    "    date_insert_query=\"insert into  \" + etl_table + \" (last_run_timestamp) values ('\" + str(dt.datetime.now()) + \"');\"\n",
    "    print(date_insert_query)\n",
    "    my_cursor.execute(date_insert_query)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    connect_mysql()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd1f19-30cc-4343-9c0a-0b008e05525f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
